{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python379jvsc74a57bd01fc8dbfc0dcd360a4d434bf7e2b03d2b730858662e47872e9ca248702abac7b4",
   "display_name": "Python 3.7.9 64-bit (conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING: this dataset doesn't have node attributes.Consider creating manual features before using it with a Loader.\n",
      "Successfully loaded COLLAB.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TUDataset(n_graphs=5000)"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "from spektral.datasets import TUDataset\n",
    "dataset = TUDataset('COLLAB')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Help on TUDataset in module spektral.datasets.tudataset object:\n\nclass TUDataset(spektral.data.dataset.Dataset)\n |  TUDataset(name, clean=False, **kwargs)\n |  \n |  The Benchmark Data Sets for Graph Kernels from TU Dortmund\n |  ([link](https://chrsmrrs.github.io/datasets/docs/datasets/)).\n |  \n |  Node features are computed by concatenating the following features for\n |  each node:\n |  \n |  - node attributes, if available;\n |  - node labels, if available, one-hot encoded.\n |  \n |  Some datasets might not have node features at all. In this case, attempting\n |  to use the dataset with a Loader will result in a crash. You can create\n |  node features using some of the transforms available in `spektral.transforms`\n |  or you can define your own features by accessing the individual samples in\n |  the `graph` attribute of the dataset (which is a list of `Graph` objects).\n |  \n |  Edge features are computed by concatenating the following features for\n |  each node:\n |  \n |  - edge attributes, if available;\n |  - edge labels, if available, one-hot encoded.\n |  \n |  Graph labels are provided for each dataset.\n |  \n |  Specific details about each individual dataset can be found in\n |  `~/.spektral/datasets/TUDataset/<dataset name>/README.md`, after the dataset\n |  has been downloaded locally (datasets are downloaded automatically upon\n |  calling `TUDataset('<dataset name>')` the first time).\n |  \n |  **Arguments**\n |  \n |  - `name`: str, name of the dataset to load (see `TUD.available_datasets`).\n |  - `clean`: if `True`, rload a version of the dataset with no isomorphic\n |             graphs.\n |  \n |  Method resolution order:\n |      TUDataset\n |      spektral.data.dataset.Dataset\n |      builtins.object\n |  \n |  Methods defined here:\n |  \n |  __init__(self, name, clean=False, **kwargs)\n |      Initialize self.  See help(type(self)) for accurate signature.\n |  \n |  download(self)\n |  \n |  read(self)\n |  \n |  ----------------------------------------------------------------------\n |  Static methods defined here:\n |  \n |  available_datasets()\n |  \n |  ----------------------------------------------------------------------\n |  Data descriptors defined here:\n |  \n |  path\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes defined here:\n |  \n |  url = 'https://www.chrsmrrs.com/graphkerneldatasets'\n |  \n |  url_clean = 'https://raw.githubusercontent.com/nd7141/graph_datasets/m...\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from spektral.data.dataset.Dataset:\n |  \n |  __getitem__(self, key)\n |  \n |  __len__(self)\n |  \n |  __repr__(self)\n |      Return repr(self).\n |  \n |  __setitem__(self, key, value)\n |  \n |  apply(self, transform)\n |  \n |  filter(self, function)\n |  \n |  map(self, transform, reduce=None)\n |  \n |  ----------------------------------------------------------------------\n |  Data descriptors inherited from spektral.data.dataset.Dataset:\n |  \n |  __dict__\n |      dictionary for instance variables (if defined)\n |  \n |  __weakref__\n |      list of weak references to the object (if defined)\n |  \n |  n_edge_features\n |  \n |  n_graphs\n |  \n |  n_labels\n |  \n |  n_node_features\n |  \n |  n_nodes\n |  \n |  signature\n |      This property computes the signature of the dataset, which can be\n |      passed to `spektral.data.utils.to_tf_signature(signature)` to compute\n |      the TensorFlow signature. You can safely ignore this property unless\n |      you are creating a custom `Loader`.\n |      \n |      A signature consist of the TensorFlow TypeSpec, shape, and dtype of\n |      all characteristic matrices of the graphs in the Dataset. This is\n |      returned as a dictionary of dictionaries, with keys `x`, `a`, `e`, and\n |      `y` for the four main data matrices.\n |      \n |      Each sub-dictionary will have keys `spec`, `shape` and `dtype`.\n\n"
     ]
    }
   ],
   "source": [
    "help(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Graph(n_nodes=45, n_node_features=None, n_edge_features=None, n_labels=3)"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}